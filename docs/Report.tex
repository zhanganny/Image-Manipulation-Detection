\documentclass[a4paper]{article}
\usepackage{geometry}
\geometry{a4paper,scale=0.7}

\usepackage[UTF8]{ctex}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{hyperref}
\usepackage{lmodern}


\title{图像篡改检测实验报告}

\author{肖圣鹏 \space 张爱玲 \space 张晓雅}

\begin{document}
\maketitle

\section{背景}
随着图像编辑技术和用户友好型编辑软件的发展，低成本的篡改图像生成过程已经广泛存在。在篡改技术中，拼接、复制-移动和删除是最常见的篡改方式。图像拼接是从真实图像中复制区域并将其粘贴到其他图像上，复制-移动则是在同一图像中复制和粘贴区域，而移除则是在真实图像中消除区域并进行涂抹。有时，在这些篡改技术之后，还会进行高斯平滑等后处理。这些篡改的例子如图\ref{fig:篡改图像示例}所示。即使仔细检查，人类也很难识别被篡改的区域。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{图1-篡改图像示例.png}
\caption{\label{fig:篡改图像示例}\textbf{经过不同篡改操作后的图像示例。}从上到下的例子显示
拼接、复制-移动和删除的操作.}
\end{figure}

因此，区分真实的图像和被篡改的图像已经变得越来越具有挑战性。以这个主题为重点的新兴研究——图像取证——具有非常重要的意义，因为它旨在防止攻击者利用其篡改的图像达到不正当的商业或政治目的。
% 与目前旨在检测图像中所有不同类别物体的物体检测网络[28, 18, 10, 32, 16, 31]相比，用于图像篡改检测的网络将旨在只检测被篡改的区域（通常是物体）。本文通过探索RGB图像内容和图像噪声特征，研究如何采用物体检测网络来进行图像篡改检测。

\section{原理}
\subsection{方法概述}
本文提出了一个新的双流图像篡改检测框架，它不仅对视觉篡改的人工制品（例如，在被篡改的边缘附近的篡改人工制品）进行建模，而且还捕捉到局部噪声特征中的不一致。

具体而言，本文在双流网络中采用了Faster R-CNN [28]，并进行端到端的训练。本文方法的概述如图\ref{fig:双流Faster R-CNN网络}所示。Faster R-CNN [28]深度学习检测模型在检测不同尺度上的语义对象方面具有良好的性能。Region Proposal Network (RPN) 是其中负责提议可能包含感兴趣图像区域的组件，它可以用于图像篡改检测。为了区分篡改区域和真实区域，本文采用双流图像篡改检测框架。第一个流利用RGB通道的特征来捕捉篡改边界处的视觉不一致性和篡改区域与真实区域之间的对比效果等线索。第二个流则分析图像中的局部噪声特征，其思路是：当一个物体从一张图像（源图像）中被移除并粘贴到另一张图像（目标图像）中时，源图像和目标图像之间的噪声特征很可能不匹配。如果用户随后对篡改后的图像进行压缩，这些差异可能会部分被掩盖[26, 4]。为了利用这些特征，本文将RGB图像转换为噪声域，并将局部噪声特征作为第二个流的输入。从图像中生成噪声特征有许多方法。基于已有的在篡改分类方面的工作，如基于丰富模型（SRM）的隐写分析 [35, 15]，本文选择SRM滤波器核来生成噪声特征，并将它们作为第二个Faster R-CNN网络的输入通道。

最后，针对每个感兴趣区域（Region of Interest，RoI），对来自这两个流的特征进行双线性池化，从而实现基于两个流的特征来检测篡改痕迹，如图\ref{fig:双流Faster R-CNN网络}所示。

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{图2-双流Faster R-CNN网络}
\caption{\label{fig:双流Faster R-CNN网络}\textbf{双流Faster R-CNN网络。}RGB流对视觉篡改工件进行建模，如沿物体边缘的异常高的对比度，并将边界框回归到真实。噪声流首先通过将输入的RGB图像通过SRM过滤层获得噪声特征图，并利用噪声特征为篡改分类提供额外证据。RGB和噪声流共享来自RPN网络的相同区域提议，该网络只使用RGB特征作为输入。RoI汇集层从RGB和噪声流中选择空间特征。预测的边界框（表示为'bbx pred'）是由RGB RoI特征生成的。在RoI池化之后的双线性池化[23, 17]层使网络能够结合来自两个流的空间共现特征。最后，将结果通过一个全连接层和一个softmax层，网络产生预测标签（表示为'cls pred'），并确定预测区域是否被操作过。}
\end{figure}

以前的图像篡改数据集[25, 1, 12, 30]只包含几百张图像，不足以训练一个深度网络。为了克服这个问题，本文创建了一个基于COCO[22]的合成篡改数据集来预训练本文的模型，然后在不同的数据集上对模型进行微调以进行测试。本文的方法在四个标准数据集上的实验结果显示了良好的性能。

% 本文的贡献有两个方面。首先，本文展示了如何以双流的方式将Faster R-CNN框架适应于图像篡改检测。本文探索了两种模态，即RGB篡改痕迹和局部噪声特征不一致性，并通过双线性池化将它们结合起来识别篡改区域。其次，本文展示了这两个流在检测不同的篡改技术方面是互补的，相比于最先进的方法，在四个图像篡改数据集上取得了更好的性能。

\subsection{详细介绍}
\subsubsection{RGB流}
RGB流是一个单一的Faster R-CNN网络，既用于边界盒回归，也用于篡改分类。本文使用ResNet 101网络[20]，从输入的RGB图像中学习特征。ResNet最后一个卷积层的输出特征被用于篡改分类。

RGB流中的RPN网络利用这些特征来提出边界盒回归的RoI。从形式上看，RPN网络的损失被定义为

\begin{equation}
L_{RPN}(g_{i}, f_{i}) = \frac{1}{N_{cls}} \sum_{i} {L_{cls}(g_{i}, g_{i}^{*})} + 
\frac{\lambda}{N_{reg}} \sum_{i} {g_{i}^{*} L_{reg}(f_{i}, f_{i}^{*})}
\end{equation}

其中，$g_{i}$ 表示第 $i$ 个锚点是一个潜在的被篡改区域的概率，$g_{i}^{*}$ 是第 $i$ 个锚点的正类标签（即真实值）。$f_{i}$ 和 $f_{i}^{*}$ 是锚点 $i$ 和真实值之间的4维边界框坐标。$L_{cls}$ 表示RPN网络的交叉熵损失，$L_{reg}$ 表示提议边界框的平滑L1损失。$N_{cls}$ 表示RPN网络中的小批量大小，$N_{reg}$ 表示锚点位置的数量。超参数 $\lambda$ 用于平衡这两个损失项，设置为10。与传统的目标检测不同，本文的RPN网络是用于搜索可能被篡改的区域，这些区域不一定是真正的对象，例如在移除篡改中的情况。

\subsubsection{噪声流}
RGB通道不足以解决所有不同的篡改情况。特别是经过精心后期处理来掩盖拼接边界和减少对比度差异的篡改图像，对RGB流来说是一个挑战。

因此，本文利用图像的局部噪声分布来提供额外的证据。与RGB流相比，噪声流被设计为更关注噪声而不是语义图像内容。虽然目前的深度学习模型在代表来自RGB图像内容的层次特征方面做得很好，但在深度学习方面，之前的工作没有研究过在检测中从噪声分布中学习。根据图像取证中SRM特征的进展[15]，本文使用SRM过滤器从RGB图像中提取局部噪声特征（图\ref{fig:篡改痕迹示例}中的例子）作为本文的噪声流的输入。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{图3-篡改痕迹示例.png}
\caption{\label{fig:篡改痕迹示例}\textbf{篡改痕迹的示例图。}两个例子展示了原始RGB图像和通过SRM滤波层获取的本地噪声特征中的篡改痕迹。第二列是第一列中红色边框放大区域。如第二列所示，棒球运动员边缘处不自然的高对比度提供了篡改存在的强烈提示。第三列展示了篡改区域与真实区域之间的本地噪声不一致性。在不同的场景中，视觉信息和噪声特征在揭示篡改痕迹方面发挥了互补作用。}
\end{figure}

在本文的设定中，噪声的模型是一个像素的值和仅通过内插邻近像素的值产生的该像素的估计值之间的残差。从30个基本过滤器开始，加上非线性操作，如过滤后附近输出的最大值和最小值，SRM特征收集了基本的噪声特征。SRM对这些滤波器的输出进行量化和截断，并提取附近的共现信息作为最终特征。从这个过程中得到的特征可以被看作是一个局部噪声描述符[7]。本文发现，只使用3个内核就可以达到像样的性能，而应用所有30个内核并不能带来明显的性能提升。因此，本文选择了3个核，其权重如图\ref{fig:三个SRM过滤层内核}所示，并将这些核直接送入一个在3个通道输入上训练的预训练网络。本文将噪声流中的SRM过滤层的核大小定义为5×5×3。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{图4-三个SRM过滤层内核.png}
\caption{\label{fig:三个SRM过滤层内核}用于提取噪声特征的三个SRM滤波器核。}
\end{figure}

在SRM层之后得到的噪声特征图显示在图\ref{fig:篡改痕迹示例}的第三列。很明显，它们强调的是局部噪声而不是图像内容，并明确揭示了在RGB通道中可能不可见的篡改假象。本文直接使用噪声特征作为噪声流网络的输入。噪声流的骨干卷积网络结构与RGB流相同。噪声流与RGB流共享相同的RoI池化层。对于边界盒回归，本文只使用RGB通道。

\subsubsection{双线性池化}
本文最终将RGB流与噪声流结合起来进行篡改检测。在各种融合方法中，本文选择对两个流的特征应用双线性池化进行融合。双线性池化最初用于细粒度分类，它在两个流的CNN网络中结合了流，并保留了空间信息以提高检测置信度。本文的双线性池化层的输出为 $x = f_{RGB}^\top f_N$，其中 $f_{RGB}$ 是RGB流的感兴趣区域（RoI）特征，$f_N$ 是噪声流的RoI特征。求和池化在分类之前对空间特征进行压缩。然后，本文在传递到全连接层之前应用有符号平方根（$x \leftarrow {sign}(x) \cdot |x|^{p}$）和L2归一化。

为了在不降低性能的情况下节省内存并加快训练速度，本文使用了紧凑型双线性池化，正如[17]中所提出的那样。在全连接层和softmax层之后，本文得到了RoI区域的预测类别，如图\ref{fig:双流Faster R-CNN网络}所示。本文使用交叉熵损失进行篡改分类，使用平滑L1损失进行边界框回归。总损失函数如下所示：

\begin{equation}
L_{total} = L_{RPN} + L_{tamper}(f_{RGB}, f_{N}) + L_{bbox}(f_{RGB})
\end{equation}

其中，$L_{total}$表示总损失。$L_{RPN}$表示RPN网络中的RPN损失。$L_{tamper}$表示最终的交叉熵分类损失，它基于来自RGB流和噪声流的双线性池化特征。$L_{bbox}$表示最终的边界框回归损失。$f_{RGB}$和$f_{N}$分别是来自RGB流和噪声流的RoI特征。所有项的求和构成了总损失函数。

\subsubsection{实施细节}
本文提出的网络是端到端的训练。输入的图像以及提取的噪声特征被重新调整大小，使其长度等于600像素。四个锚点的尺寸从$8^2$、$16^2$、$32^2$到$64^2$，长宽比为1：2、1：1和2：1。对RGB和噪声流进行RoI汇集后的特征大小为7×7×1024。紧凑型双线性池的输出特征大小被设定为16384。RPN建议的批次大小为：训练64，测试300。

图像翻转被用于数据增强。RPN正例（潜在的被篡改区域）的交叉联合（IoU）阈值为0.7，负例（真实区域）为0.3。学习率最初被设定为0.001，然后在40K步之后被降低到0.0001。本文对本文的模型进行了110K步的训练。在测试时，应用标准的非最大抑制（NMS）来减少拟议中的重叠区域的冗余度。NMS的阈值被设置为0.2。

\section{实验}

\end{document}